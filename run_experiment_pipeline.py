"""
FIXED: Comprehensive Experiment Runner
=======================================
Orchestrates the complete experimental pipeline:
1. Generate synthetic data (with proper train/test split)
2. Train models with proper evaluation
3. Run multi-run experiments for statistical rigor
4. Run ablation studies
5. Generate publication-ready tables and plots
"""

import argparse
import subprocess
import sys
import json
import os
import numpy as np
from datetime import datetime
from pathlib import Path

# Add project root for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from utils.reproducibility import set_seeds

# Initialize seeds for reproducibility
set_seeds(42)


def run_command(cmd: str, description: str) -> bool:
    """Run a shell command and report results"""
    print(f"\n{'='*70}")
    print(f"STEP: {description}")
    print(f"{'='*70}")
    print(f"Running: {cmd}\n")
    
    result = subprocess.run(cmd, shell=True, capture_output=False)
    
    if result.returncode == 0:
        print(f"âœ“ {description} COMPLETED SUCCESSFULLY")
        return True
    else:
        print(f"âœ— {description} FAILED")
        return False


def run_experiment_pipeline(args):
    """
    Run complete experiment pipeline
    """
    print("\n" + "â–ˆ"*70)
    print("â–ˆ" + " "*68 + "â–ˆ")
    print("â–ˆ" + "COMPREHENSIVE EXPERIMENT PIPELINE".center(68) + "â–ˆ")
    print("â–ˆ" + " "*68 + "â–ˆ")
    print("â–ˆ"*70)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_dir = f"experiments/exp_{timestamp}"
    os.makedirs(experiment_dir, exist_ok=True)
    
    log_file = f"{experiment_dir}/experiment_log.txt"
    
    # Redirect stdout to log file
    with open(log_file, "w") as f:
        f.write(f"EXPERIMENT RUN: {timestamp}\n")
        f.write(f"{'='*70}\n\n")
    
    # Step 1: Generate synthetic data
    if not os.path.exists("data/processed/synth_balanced_train.json"):
        if not run_command(
            f"{sys.executable} preprocess/generate_fixed_dataset.py",
            "Generate Synthetic Data with Fixed Statistics"
        ):
            return False
    else:
        print("\nâœ“ Synthetic data already exists, skipping generation")
    
    # Step 2: Run single training experiment
    if not run_command(
        f"{sys.executable} train/train_fixed.py --max_epochs {args.max_epochs} --seed 42",
        "Train Model (Single Run, Seed=42)"
    ):
        return False
    
    # Step 3: Run multi-run experiments
    if args.num_runs > 1:
        if not run_command(
            f"{sys.executable} evaluate_multirun_fixed.py --num_runs {args.num_runs} --max_epochs {args.max_epochs}",
            f"Multi-Run Evaluation ({args.num_runs} runs with different seeds)"
        ):
            return False
    
    # Step 4: Run ablation study
    if args.ablation:
        if not run_command(
            f"{sys.executable} evaluate_ablation_fixed.py --max_epochs {args.max_epochs}",
            "Ablation Study (Component Importance Analysis)"
        ):
            return False
    
    # Step 5: Generate summary report
    generate_summary_report(experiment_dir)
    
    print("\n" + "â–ˆ"*70)
    print("â–ˆ" + " "*68 + "â–ˆ")
    print("â–ˆ" + "EXPERIMENT PIPELINE COMPLETED".center(68) + "â–ˆ")
    print("â–ˆ" + " "*68 + "â–ˆ")
    print("â–ˆ"*70)
    print(f"\nðŸ“Š Results saved to: {experiment_dir}")
    print(f"ðŸ“„ Log file: {log_file}")


def generate_summary_report(experiment_dir: str):
    """Generate summary report from results"""
    print("\n" + "="*70)
    print("GENERATING SUMMARY REPORT")
    print("="*70)
    
    report_path = f"{experiment_dir}/summary_report.md"
    
    with open(report_path, "w") as f:
        f.write("# Experiment Summary Report\n\n")
        f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # Load and summarize results
        f.write("## Results\n\n")
        
        # Single run results
        single_run_path = "outputs/training_log_seed42.json"
        if os.path.exists(single_run_path):
            with open(single_run_path) as rf:
                data = json.load(rf)
                f.write("### Single Run (Seed=42)\n\n")
                f.write("| Metric | Value |\n")
                f.write("|--------|-------|\n")
                for metric, value in data.items():
                    if metric != "training_loss_per_epoch":
                        f.write(f"| {metric} | {value:.4f} |\n")
        
        # Multi-run results
        multi_run_path = "outputs/multi_run_results.json"
        if os.path.exists(multi_run_path):
            with open(multi_run_path) as rf:
                data = json.load(rf)
                f.write("\n### Multi-Run Results (5 runs)\n\n")
                f.write("| Metric | Mean | Std | 95% CI |\n")
                f.write("|--------|------|-----|--------|\n")
                for metric, stats in data.get("aggregated_stats", {}).items():
                    mean = stats.get("mean", 0)
                    std = stats.get("std", 0)
                    ci_lower = stats.get("ci_lower", 0)
                    ci_upper = stats.get("ci_upper", 0)
                    f.write(f"| {metric} | {mean:.4f} | {std:.4f} | [{ci_lower:.4f}, {ci_upper:.4f}] |\n")
        
        # Ablation results
        ablation_path = "outputs/ablation_study_results.json"
        if os.path.exists(ablation_path):
            with open(ablation_path) as rf:
                data = json.load(rf)
                f.write("\n### Ablation Study\n\n")
                f.write("| Variant | F1 | AUC | Status |\n")
                f.write("|---------|----|----|--------|\n")
                for variant, results in data.items():
                    if results.get("metrics"):
                        f1 = results["metrics"].get("f1", 0)
                        auc = results["metrics"].get("auc", 0)
                        status = "âœ“"
                    else:
                        f1 = auc = 0
                        status = "âœ—"
                    f.write(f"| {variant} | {f1:.4f} | {auc:.4f} | {status} |\n")
        
        f.write("\n## Interpretation\n\n")
        f.write("- All models trained on fixed dataset with proper train/test split\n")
        f.write("- Threshold tuned on validation set to maximize F1\n")
        f.write("- Results should show clear improvement from 0.5 baseline\n")
        f.write("- Multi-run CV shows stability across random seeds\n")
        f.write("- Ablation study identifies critical components\n")
    
    print(f"âœ“ Summary report saved to: {report_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run comprehensive experiment pipeline"
    )
    parser.add_argument("--max_epochs", type=int, default=20,
                        help="Maximum training epochs")
    parser.add_argument("--num_runs", type=int, default=5,
                        help="Number of runs for multi-run evaluation")
    parser.add_argument("--ablation", action="store_true",
                        help="Run ablation study")
    parser.add_argument("--quick", action="store_true",
                        help="Quick run (5 epochs, 2 runs)")
    
    args = parser.parse_args()
    
    # Quick mode overrides
    if args.quick:
        args.max_epochs = 5
        args.num_runs = 2
    
    run_experiment_pipeline(args)
