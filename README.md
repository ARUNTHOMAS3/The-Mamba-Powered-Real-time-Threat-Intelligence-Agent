# Efficient Real-Time Intrusion Detection via State Space Models: A Comprehensive Benchmark

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Comprehensive benchmark study comparing State Space Models (Mamba), Transformers, and Recurrent Neural Networks for network intrusion detection across multiple datasets.**

---

## ğŸ¯ Overview

This repository provides a **rigorous, fair, and reproducible** benchmark comparing **6 sequence-modeling architectures** for Network Intrusion Detection Systems (NIDS), evaluated across **3 standard datasets** with **5 random seeds** and full statistical significance testing.

### Models Compared

| Model | Type | Key Mechanism |
|-------|------|---------------|
| **Mamba (SSM)** | State Space Model | Selective scan, linear-time sequence modeling |
| **LSTM** | Recurrent | Gated memory cells |
| **GRU** | Recurrent | Gated recurrent unit (simplified LSTM) |
| **Transformer** | Attention-based | Multi-head self-attention |
| **CNN-LSTM** | Hybrid | 1D-CNN local features + LSTM temporal |
| **TCN** | Convolutional | Dilated causal convolutions |

### Datasets

| Dataset | Year | Samples | Features | Attack Types |
|---------|------|---------|----------|--------------|
| CICIDS2017 | 2017 | ~2.8M | 77 | DDoS, PortScan, Bot, etc. |
| UNSW-NB15 | 2015 | ~2.5M | 49 | Fuzzers, Exploits, DoS, etc. |
| CIC-IDS2018 | 2018 | ~16M | 80 | Brute Force, DoS, Botnet, etc. |

### Key Contributions

1. **First comprehensive SSM benchmark for IDS** â€” Systematic comparison of Mamba vs attention-based and recurrent models
2. **Fair evaluation framework** â€” All models use identical hyperparameters, matched parameter counts (within Â±15%), and the same data pipeline
3. **Multi-dimensional analysis** â€” Classification accuracy, computational efficiency (latency, throughput, memory), and per-attack-type breakdown
4. **Statistical rigor** â€” 5-seed evaluation with Wilcoxon signed-rank tests and 95% confidence intervals

---

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/yourusername/mamba-threat-intel.git
cd mamba-threat-intel

python -m venv .venv
.\.venv\Scripts\Activate.ps1  # Windows
# source .venv/bin/activate    # Linux/Mac

pip install -r requirements.txt
```

### Dataset Setup

Download datasets into `data/raw/`:

| Dataset | Download |
|---------|----------|
| CICIDS2017 | [UNB Website](https://www.unb.ca/cic/datasets/ids-2017.html) â†’ `data/raw/CICIDS2017/` |
| UNSW-NB15 | [UNSW Website](https://research.unsw.edu.au/projects/unsw-nb15-dataset) â†’ `data/raw/UNSW-NB15/` |
| CIC-IDS2018 | `aws s3 sync --no-sign-request --region ap-south-1 "s3://cse-cic-ids2018/Processed Traffic Data for ML Algorithms/" data/raw/CIC-IDS2018/ --exclude "*" --include "*.csv"` |

### Run Benchmark

```bash
# Full benchmark (all datasets, all models, 5 seeds)
python run_benchmark.py

# Quick test (single dataset, 2 models, 1 seed)
python run_benchmark.py --datasets CICIDS2017 --models Mamba LSTM --seeds 42 --quick

# Specific configuration
python run_benchmark.py --datasets CICIDS2017 UNSW-NB15 --models Mamba LSTM GRU Transformer --seeds 42 123 456
```

### Generate Publication Tables

```bash
python generate_tables.py
```

---

## ğŸ“ Project Structure

```
mamba-threat-intel/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mamba_backbone.py       # Mamba SSM (pure PyTorch S6 implementation)
â”‚   â”œâ”€â”€ tabular_models.py       # MambaClassifier + LSTMClassifier
â”‚   â””â”€â”€ benchmark_models.py     # GRU, Transformer, CNN-LSTM, TCN + model registry
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ cicids2017_loader.py    # CICIDS2017 loader (lazy windowing, temporal split)
â”‚   â”œâ”€â”€ unswnb15_loader.py      # UNSW-NB15 loader
â”‚   â”œâ”€â”€ cicids2018_loader.py    # CIC-IDS2018 loader
â”‚   â””â”€â”€ dataset_factory.py     # Unified dataset factory
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ experiment.yaml         # Single source of truth for all hyperparameters
â”‚
â”œâ”€â”€ run_benchmark.py            # Main benchmark runner (single entry point)
â”œâ”€â”€ evaluate.py                 # Evaluation metrics, efficiency, statistical tests
â”œâ”€â”€ generate_tables.py          # Publication table generator
â”œâ”€â”€ verify_benchmark.py         # Verification script
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ reproducibility.py      # Seed setting, system info logging
â”‚   â”œâ”€â”€ config_loader.py        # YAML config loader
â”‚   â””â”€â”€ metrics.py              # Classification metrics
â”‚
â””â”€â”€ outputs/
    â””â”€â”€ benchmark_results/      # All experiment results (JSON)
```

---

## ğŸ”¬ Experimental Protocol

### Fair Comparison Guarantees

All models are compared under **strictly identical conditions**:

- âœ… **Same data pipeline**: Identical preprocessing, windowing, and temporal splits (70/10/20)
- âœ… **Same hyperparameters**: Learning rate, batch size, optimizer, loss function
- âœ… **Matched capacity**: All models are within Â±15% parameter count
- âœ… **No data leakage**: Scaler fitted on training set only, strict temporal ordering
- âœ… **No shuffling**: Preserves temporal causality
- âœ… **Early stopping**: Patience=5 on validation F1

### Evaluation Metrics

**Classification**: Accuracy, Precision, Recall, F1-Score, AUC-ROC

**Efficiency**: Inference latency (ms), throughput (samples/sec), memory footprint (MB), parameter count

**Analysis**: Per-attack-type F1 breakdown, statistical significance (Wilcoxon signed-rank, p<0.05)

### Reproducibility

- 5 fixed random seeds (42, 123, 456, 789, 1024)
- Deterministic PyTorch operations enabled
- System info and config hash logged for every run
- All results saved as JSON for independent verification

---

## ğŸ“Š Configuration

All hyperparameters are controlled from a single file: [`configs/experiment.yaml`](configs/experiment.yaml)

```yaml
datasets: [CICIDS2017, UNSW-NB15, CIC-IDS2018]
models: [Mamba, LSTM, GRU, Transformer, CNN-LSTM, TCN]
seeds: [42, 123, 456, 789, 1024]

dataset:
  seq_len: 50
model:
  d_model: 128
  n_layers: 2
training:
  batch_size: 128
  epochs: 30
  learning_rate: 0.001
  early_stopping:
    patience: 5
```

---

## ğŸ“„ License

MIT License

---

## ğŸ™ Acknowledgments

- Mamba SSM: [Gu & Dao, 2023](https://arxiv.org/abs/2312.00752)
- CICIDS2017: [Sharafaldin et al., 2018](https://www.unb.ca/cic/datasets/ids-2017.html)
- UNSW-NB15: [Moustafa & Slay, 2015](https://research.unsw.edu.au/projects/unsw-nb15-dataset)
- CIC-IDS2018: [CSE-CIC-IDS2018](https://www.unb.ca/cic/datasets/ids-2018.html)
